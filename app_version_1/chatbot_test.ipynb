{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm just a computer program, so I don't have feelings, but thanks for asking! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "AZURE_API_KEY = '5f3dfecbd34d4bed939cd0e4b7abed63'  # Replace with your actual API key\n",
    "AZURE_ENDPOINT = 'https://prof-insight-ai-service.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview'\n",
    "\n",
    "def get_azure_response(user_input):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'api-key': AZURE_API_KEY\n",
    "    }\n",
    "    \n",
    "    # Constructing the data payload for chat models\n",
    "    data = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ],\n",
    "        \"max_tokens\": 500  # Control response length\n",
    "    }\n",
    "    \n",
    "    response = requests.post(AZURE_ENDPOINT, headers=headers, json=data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        return response_json['choices'][0]['message']['content']  # Get response text\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}, {response.text}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axel is a name that can refer to different individuals in various contexts, each possibly having distinct roles or professions. Without additional information, it's challenging to pinpoint what a specific \"Axel\" does. However, I can provide some general examples:\n",
      "\n",
      "1. **Axel in Literature or Media**: There could be characters named Axel in books, movies, or TV shows who have specific roles or story arcs. For instance, Axel Foley is a famous character played by Eddie Murphy in the \"Beverly Hills Cop\" movie series, where he is a detective.\n",
      "\n",
      "2. **Axel in Technology or Business**: There might be individuals named Axel in the tech or business world who could be CEOs, developers, entrepreneurs, or any other professional role.\n",
      "\n",
      "3. **Axel in Sports**: This could be in reference to athletes, such as professional skaters or soccer players.\n",
      "\n",
      "4. **Axel in Music**: Axel could be the name of musicians, composers, or singers.\n",
      "\n",
      "5. **Axel in Everyday Life**: Axel might be an ordinary person's first name, applicable to any number of professions or daily activities.\n",
      "\n",
      "To provide a more accurate answer, you would need to specify the context in which you are referring to Axel.\n"
     ]
    }
   ],
   "source": [
    "user_input = 'What does Axel do generally'\n",
    "response = get_azure_response(user_input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Azure Search configuration\n",
    "search_service_endpoint = \"https://prof-insight-search.search.windows.net\"\n",
    "index_name = \"prof-insight-index\"\n",
    "api_key = \"9K3QkXHzTrk6kPP78fjug3NSG3U93HQMK28pEXF5oLAzSeDWVa3i\"\n",
    "\n",
    "# Create Azure Search client\n",
    "search_client = SearchClient(endpoint=search_service_endpoint,\n",
    "                             index_name=index_name,\n",
    "                             credential=AzureKeyCredential(api_key))\n",
    "\n",
    "# Azure OpenAI configuration\n",
    "AZURE_API_KEY = '5f3dfecbd34d4bed939cd0e4b7abed63'\n",
    "AZURE_ENDPOINT = 'https://prof-insight-ai-service.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview'\n",
    "\n",
    "def retrieve_context(user_input):\n",
    "    results = search_client.search(search_text=user_input)\n",
    "    relevant_contexts = [result['text'] for result in results]  # Adjust 'content' to your actual field\n",
    "    return \"\\n\".join(relevant_contexts) if relevant_contexts else \"No relevant context found.\"\n",
    "\n",
    "def get_azure_response(user_input, context):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'api-key': AZURE_API_KEY\n",
    "    }\n",
    "    \n",
    "    # Combine context with user input\n",
    "    combined_input = f\"Context:\\n{context}\\n\\nUser: {user_input}\"\n",
    "    \n",
    "    data = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": combined_input}\n",
    "        ],\n",
    "        \"max_tokens\": 500\n",
    "    }\n",
    "    \n",
    "    response = requests.post(AZURE_ENDPOINT, headers=headers, json=data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        return response_json['choices'][0]['message']['content']\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}, {response.text}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"How are you?\" \n",
    "relevant_context = search_client.search(search_text=user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "azure.search.documents._paging.SearchItemPaged"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(relevant_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Main logic\u001b[39;00m\n\u001b[1;32m      2\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow are you?\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Example user input\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[43mretrieve_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m response \u001b[38;5;241m=\u001b[39m get_azure_response(user_input, context)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProf-insight:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m, in \u001b[0;36mretrieve_context\u001b[0;34m(user_input)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretrieve_context\u001b[39m(user_input):\n\u001b[1;32m     20\u001b[0m     results \u001b[38;5;241m=\u001b[39m search_client\u001b[38;5;241m.\u001b[39msearch(search_text\u001b[38;5;241m=\u001b[39muser_input)\n\u001b[0;32m---> 21\u001b[0m     relevant_contexts \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Adjust 'content' to your actual field\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(relevant_contexts) \u001b[38;5;28;01mif\u001b[39;00m relevant_contexts \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo relevant context found.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretrieve_context\u001b[39m(user_input):\n\u001b[1;32m     20\u001b[0m     results \u001b[38;5;241m=\u001b[39m search_client\u001b[38;5;241m.\u001b[39msearch(search_text\u001b[38;5;241m=\u001b[39muser_input)\n\u001b[0;32m---> 21\u001b[0m     relevant_contexts \u001b[38;5;241m=\u001b[39m [\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results]  \u001b[38;5;66;03m# Adjust 'content' to your actual field\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(relevant_contexts) \u001b[38;5;28;01mif\u001b[39;00m relevant_contexts \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo relevant context found.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "# Main logic\n",
    "\n",
    " # Example user input\n",
    "context = retrieve_context(user_input)\n",
    "response = get_azure_response(user_input, context)\n",
    "print(f\"Prof-insight:\\n{response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SearchIndexClient' from 'azure.search.documents' (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/azure/search/documents/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msearch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocuments\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SearchClient, SearchIndexClient\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcredentials\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureKeyCredential\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Azure Search configuration\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'SearchIndexClient' from 'azure.search.documents' (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/azure/search/documents/__init__.py)"
     ]
    }
   ],
   "source": [
    "from azure.search.documents import SearchClient, SearchIndexClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Azure Search configuration\n",
    "search_service_endpoint = \"https://prof-insight-search.search.windows.net\"\n",
    "api_key = \"9K3QkXHzTrk6kPP78fjug3NSG3U93HQMK28pEXF5oLAzSeDWVa3i\"\n",
    "index_name = \"prof-insight-index\"\n",
    "\n",
    "# Create an index client\n",
    "index_client = SearchIndexClient(endpoint=search_service_endpoint, credential=AzureKeyCredential(api_key))\n",
    "\n",
    "def list_index_fields(index_name):\n",
    "    index = index_client.get_index(index_name)\n",
    "    print(\"Fields in index:\")\n",
    "    for field in index.fields:\n",
    "        print(f\"- {field.name} (type: {field.type})\")\n",
    "\n",
    "# Call the function to list fields\n",
    "list_index_fields(index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "\n",
    "endpoint = 'https://prof-insight-ai-service.cognitiveservices.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-03-15-preview'\n",
    "api_key = '5f3dfecbd34d4bed939cd0e4b7abed63'\n",
    "deployment = 'gpt-4o'\n",
    "\n",
    "client = openai.AzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=api_key,\n",
    "    api_version=\"2024-02-01\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What are my available health plans?\",\n",
    "        },\n",
    "    ],\n",
    "    extra_body={\n",
    "        \"data_sources\":[\n",
    "            {\n",
    "                \"type\": \"azure_search\",\n",
    "                \"parameters\": {\n",
    "                    \"endpoint\": 'https://prof-insight-search.search.windows.net',\n",
    "                    \"index_name\": 'prof-insight-index',\n",
    "                    \"authentication\": {\n",
    "                        \"type\": \"api_key\",\n",
    "                        \"key\": 'os.environ[\"AZURE_AI_SEARCH_API_KEY\"]',\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"53895d84-9e08-47e1-be7c-62b81c6def03\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"The requested information is not available in the retrieved data. Please try another query or topic.\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": null,\n",
      "        \"end_turn\": true,\n",
      "        \"context\": {\n",
      "          \"citations\": [\n",
      "            {\n",
      "              \"content\": \"In the original version of this Article, the affiliation details for Jadranka Loncarek and Vito Mennella were incorrectly given as 'Cell Biology Program, The Hospital for Sick Children, Department of Biochemistry, University of Toronto, 555 University Avenue, Toronto, ON, M5G 1X8, Canada' and 'Laboratory of Protein Dynamics and Signaling, Center for Cancer Research, National Cancer Institute, 1050 Boyles Street, Frederick, MD, 21702, USA', respectively. This has now been corrected in both the PDF and HTML versions of the Article.\\nnature communications\\n[]\\nSchatten Gerald\\nUniversity_of_Pittsburgh\",\n",
      "              \"title\": \"Author Correction: A novel atypical sperm centriole is functional during human fertilization.\",\n",
      "              \"url\": null,\n",
      "              \"filepath\": null,\n",
      "              \"chunk_id\": \"0\"\n",
      "            },\n",
      "            {\n",
      "              \"content\": \"BACKGROUND: Well-being has multiple domains, and these domains are unique to the population being examined. Therefore, to precisely assess the well-being of a population, a scale specifically designed for that population is needed. OBJECTIVE: The goal of this study was to design and validate a comprehensive well-being scale for people in a university environment, including students, faculty, and staff. METHODS: A crowdsourcing approach was used to determine relevant domains for the comprehensive well-being scale in this population and identify specific questions to include in each domain. A web-based questionnaire (Q1) was used to collect opinions from a group of university students, faculty, and staff about the domains and subdomains of the scale. A draft of a new well-being scale (Q2) was created in response to the information collected via Q1, and a second group of study participants was invited to evaluate the relevance and clarity of each statement. A newly created well-being scale (Q3) was then used by a third group of university students, faculty, and staff. A psychometric analysis was performed on the data collected via Q3 to determine the validity and reliability of the well-being scale. RESULTS: In the first step, a group of 518 university community members (students, faculty, and staff) indicated the domains and subdomains that they desired to have in a comprehensive well-being scale. In the second step, a second group of 167 students, faculty, and staff evaluated the relevance and clarity of the proposed statements in each domain. In the third step, a third group of 546 students, faculty, and staff provided their responses to the new well-being scale (Pitt Wellness Scale). The psychometric analysis indicated that the reliability of the well-being scale was high. CONCLUSIONS: Using a crowdsourcing approach, we successfully created a comprehensive and highly reliable well-being scale for people in the university environment. Our new Pitt Wellness Scale may be used to measure the well-being of people in the university environment.\\njournal of medical internet research\\n['crowdsourcing', 'questionnaire design', 'university']\\nZhou Leming\\nUniversity_of_Pittsburgh\",\n",
      "              \"title\": \"Development and Validation of a Comprehensive Well-Being Scale for People in the University Environment (Pitt Wellness Scale) Using a Crowdsourcing Approach: Cross-Sectional Study.\",\n",
      "              \"url\": null,\n",
      "              \"filepath\": null,\n",
      "              \"chunk_id\": \"0\"\n",
      "            },\n",
      "            {\n",
      "              \"content\": \"OBJECTIVES: Proprioception is important because it is used by the central nervous system to mediate muscle control of joint stability, posture, and movement. Knee active joint position sense (AJPS) is one representation of knee proprioception. The purpose of this study was to establish the intra-tester, inter-session, test-retest reliability of concentric-to-isometric (seated knee extension; prone knee flexion) and eccentric-to-isometric (seated knee flexion; prone knee extension) knee AJPS tests in uninjured adults. DESIGN: Descriptive. SETTING: University laboratory. PARTICIPANTS: Six males, six females (age 26.2 ± 5.7 years; height 171.1 ± 9.6 cm; mass 71.1 ± 16.6 kg). MAIN OUTCOME MEASURES: Mean absolute error (AE; °); intraclass correlation coefficient (ICC) (2,1); standard error of measurement (SEM; °). RESULTS: Mean AE ranged from 3.18° to 5.97° across tests. The ICCs and SEMs were: seated knee extension 0.13, 1.3°; prone knee flexion 0.51, 1.2°; seated knee flexion 0.31, 1.7°; prone knee extension 0.87, 1.4°. CONCLUSIONS: The prone knee flexion and prone knee extension tests demonstrated moderate to good reliability. Prone knee flexion and prone knee extension AJPS tests may be useful in cross-sectional studies estimating how proprioception contributes to knee functional joint stability or prospective studies estimating the role of proprioception in the onset of knee injury.\\ninjury-international journal of the care of the injured\\n['active joint position sense', 'knee', 'proprioception', 'reliability']\\nSell Timothy\\nUniversity_of_Pittsburgh\",\n",
      "              \"title\": \"Reliability and measurement precision of concentric-to-isometric and eccentric-to-isometric knee active joint position sense tests in uninjured physically active adults.\",\n",
      "              \"url\": null,\n",
      "              \"filepath\": null,\n",
      "              \"chunk_id\": \"0\"\n",
      "            },\n",
      "            {\n",
      "              \"content\": \"Humanity is experiencing a catastrophic pandemic. SARS-CoV-2 has spread globally to cause significant morbidity and mortality, and there still remain unknowns about the biology and pathology of the virus. Even with testing, tracing, and social distancing, many countries are struggling to contain SARS-CoV-2. COVID-19 will only be suppressible when herd immunity develops, either because of an effective vaccine or if the population has been infected and is resistant to reinfection. There is virtually no chance of a return to pre-COVID-19 societal behavior until there is an effective vaccine. Concerted efforts by physicians, academic laboratories, and companies around the world have improved detection and treatment and made promising early steps, developing many vaccine candidates at a pace that has been unmatched for prior diseases. As of August 11, 2020, 28 of these companies have advanced into clinical trials with Moderna, CanSino, the University of Oxford, BioNTech, Sinovac, Sinopharm, Anhui Zhifei Longcom, Inovio, Novavax, Vaxine, Zydus Cadila, Institute of Medical Biology, and the Gamaleya Research Institute having moved beyond their initial safety and immunogenicity studies. This review analyzes these frontrunners in the vaccine development space and delves into their posted results while highlighting the role of the nanotechnologies applied by all the vaccine developers.\\nacs nano\\n['astrazeneca', 'biontech', 'cansino', 'moderna', 'mrna', 'pfizer', 'sars-cov-2', 'university of oxford', 'vaccine', 'viral vector']\\nNicole Steinmetz\\nUniversity_of_California_San_Diego\",\n",
      "              \"title\": \"COVID-19 Vaccine Frontrunners and Their Nanotechnology Design.\",\n",
      "              \"url\": null,\n",
      "              \"filepath\": null,\n",
      "              \"chunk_id\": \"0\"\n",
      "            },\n",
      "            {\n",
      "              \"content\": \"PURPOSE: Effective communication among healthcare workers is critically important for patient safety and quality care. The purpose of this pilot study was to evaluate outcomes of a workshop designed to teach Chinese nursing students to use the Situation-Background-Assessment-Recommendation (SBAR) communication tool and examine their attitudes toward utilizing SBAR as a communication tool. METHOD: A convenience sample of 18 master's degree nursing students at a Chinese university was introduced to SBAR through a workshop. The workshop combined the SBAR tool, video-stimulated recall and role-play case scenarios to illustrate potential positive and negative communication-related patient outcomes. Students completed a 12-item questionnaire before and after participating in the workshop. Four of the items examined the four elements of the SBAR tool (situation, background, assessment, recommendation, score range 0-20), and eight of the items evaluated students' self-perceived attitudes towards utilizing the SBAR tool in their clinical practice (score range 0-40). RESULTS: Pre- and post-workshop scores on the four elements of the SBAR tool demonstrate significant improvement in knowledge of SBAR (14.0±2.9 vs. 16.6±2.2, respectively; p=0.009). Pre- and post-workshop scores on the items testing students' self-perceived abilities also demonstrate significant improvement (26.9±3.5 vs. 32.6±4.5, respectively; p&lt;0.01) in using SBAR. Total scores increased significantly from 40.9±5.0 to 49.2±5.9 (p&lt;0.01). Moreover, 93.8% of the students agreed and strongly agreed that they would use SBAR during clinical practice. CONCLUSION: Participating in the SBAR workshop in combination with video-stimulated recall and role-play case scenarios significantly improved the Chinese nursing students' knowledge of SBAR and their self-perceived attitudes towards using SBAR tool. Future studies using a larger sample size and longer post-workshop follow-up are needed to confirm the long-term benefits of the workshop.\\nnurse education today\\n['communication inter-professional communication', 'nursing education', 'role-play case scenarios', 'sbar', 'video-stimulated recall']\\nZhan Liang\\nUniversity_of_Pittsburgh\",\n",
      "              \"title\": \"Improving Chinese nursing students' communication skills by utilizing video-stimulated recall and role-play case scenarios to introduce them to the SBAR technique.\",\n",
      "              \"url\": null,\n",
      "              \"filepath\": null,\n",
      "              \"chunk_id\": \"0\"\n",
      "            }\n",
      "          ],\n",
      "          \"intent\": \"[\\\"Axel Guenther role at University of Toronto\\\", \\\"Axel Guenther University of Toronto\\\", \\\"Axel Guenther position at University of Toronto\\\"]\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1727451016,\n",
      "  \"model\": \"gpt-4o\",\n",
      "  \"object\": \"extensions.chat.completion\",\n",
      "  \"service_tier\": null,\n",
      "  \"system_fingerprint\": \"fp_67802d9a6d\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 52,\n",
      "    \"prompt_tokens\": 4255,\n",
      "    \"total_tokens\": 4307\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
